{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26800739",
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_data_v2 import get_dataloader_v2\n",
    "from get_data import get_dataloader\n",
    "import pathlib\n",
    "import torch \n",
    "from tqdm import tqdm \n",
    "from train import get_needed_metrics\n",
    "from efficient_net import Efficient_Net\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = '/home/shirshak/Thesis_Data/DOES/TEST_raw/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166ea5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = get_dataloader(test_path, get_path=True, batch_size = 128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a43b65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "root=pathlib.Path(test_path)\n",
    "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257eb64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Efficient_Net(classes=classes)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "model.to(device)\n",
    "checkpoint_path = \"/home/shirshak/Thesis_Classification_Code/model_best_val_f1.pth\"\n",
    "checkpoint = torch.load(checkpoint_path, weights_only=False)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bc42a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "acc_test_epoch, precision_test_epoch, recall_test_epoch, f1_test_epoch  = [], [], [], []\n",
    "\n",
    "overall_input, overall_labels, overall_predicted, overall_image_path = [], [], [], []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels, image_path in tqdm(test_loader, desc=f'Testing', unit='batch'):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        test_loss = loss_func(outputs, labels)\n",
    "        _, predicted_test = torch.max(outputs, 1)\n",
    "\n",
    "        overall_input.extend(inputs)\n",
    "        overall_labels.extend(labels)\n",
    "        overall_predicted.extend(predicted_test)\n",
    "        overall_image_path.extend(image_path)\n",
    "\n",
    "        acc_batch_test, precision_batch_test, recall_batch_test, f1_batch_test = get_needed_metrics(labels.cpu().detach().tolist(), predicted_test.cpu().detach().tolist())\n",
    "\n",
    "        acc_test_epoch.append(acc_batch_test)\n",
    "        precision_test_epoch.append(precision_batch_test)\n",
    "        recall_test_epoch.append(recall_batch_test)\n",
    "        f1_test_epoch.append(f1_batch_test)\n",
    "\n",
    "\n",
    "    print(\n",
    "        f'Val Loss: {test_loss.item():.4f}, '\n",
    "        f'Val Accuracy: {torch.tensor(acc_test_epoch).mean() * 100:.2f}%, '\n",
    "        f'Val Precision: {torch.tensor(precision_test_epoch).mean() * 100:.2f}%, '\n",
    "        f'Val Recall: {torch.tensor(recall_test_epoch).mean() * 100:.2f}%, '\n",
    "        f'Val F1: {torch.tensor(f1_test_epoch).mean() * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eae48bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_labels, overall_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c747bcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_chart = confusion_matrix(torch.tensor(overall_labels).cpu(), torch.tensor(overall_predicted).cpu())\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_chart, display_labels = ['BG', 'E1', 'E2', 'E3', 'E40', 'E5H', 'E6', 'E8', 'EHRB'])\n",
    "\n",
    "cm_display.plot()\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.savefig('confusion_matrix.png', dpi=500)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e492d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "right_cases = [(x_w, y_w, yp_w, img_p) for x_w, y_w, yp_w, img_p in zip(overall_input, overall_labels, overall_predicted, overall_image_path) if y_w == yp_w]\n",
    "wrong_cases = [(x_w, y_w, yp_w, img_p) for x_w, y_w, yp_w, img_p in zip(overall_input, overall_labels, overall_predicted, overall_image_path) if y_w != yp_w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df7de32",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4766dd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_right_examples = random.sample(right_cases, min(20, len(right_cases)))\n",
    "\n",
    "for count, right_case in enumerate(some_right_examples):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(5, 5))\n",
    "    \n",
    "    ax[0].imshow(Image.open(right_case[3]))\n",
    "    ax[0].set_title('Original Image')\n",
    "    ax[0].axis('off')\n",
    "    ax[0].text(0.5, -0.1, f'Real : {classes[right_case[1]]}', ha='center', va='center', transform=ax[0].transAxes, fontsize=10)\n",
    "\n",
    "    ax[1].imshow(torchvision.transforms.ToPILImage()(right_case[0]))\n",
    "    ax[1].set_title('Transformed Image')\n",
    "    ax[1].axis('off')\n",
    "    ax[1].text(0.5, -0.1, f'Predicted : {classes[right_case[2]]}', ha='center', va='center', transform=ax[1].transAxes, fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(f\"/home/shirshak/Glaucoma_Efficientnet_simple/glaucoma_test_images/correct{count}.jpg\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77d5069",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_wrong_examples = random.sample(wrong_cases, min(20, len(wrong_cases)))\n",
    "\n",
    "for count,wrong_case in enumerate(some_wrong_examples):\n",
    "    fig, ax = plt.subplots(1,2, figsize=(5,5))\n",
    "\n",
    "    ax[0].imshow(Image.open(wrong_case[3]))\n",
    "    ax[0].set_title('Original Image')\n",
    "    ax[0].axis('off')\n",
    "    ax[0].text(0.5, -0.1, f'Real : {classes[wrong_case[1]]}', ha='center', va='center', transform=ax[0].transAxes, fontsize=10)\n",
    "\n",
    "    ax[1].imshow(torchvision.transforms.ToPILImage()(wrong_case[0]))\n",
    "    ax[1].set_title('Transformed Image')\n",
    "    ax[1].axis('off')\n",
    "    ax[1].text(0.5, -0.1, f'Predicted : {classes[wrong_case[2]]}', ha='center', va='center', transform=ax[1].transAxes, fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # plt.savefig(f\"/home/shirshak/Glaucoma_Efficientnet_simple/glaucoma_test_images/wrong{count}.jpg\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c784c3bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd39bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e6b197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c89362f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6085820",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
